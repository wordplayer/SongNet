{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Read the Spotify playlists dataset, rearranged as a Pandas dataframe, from a pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open('playlists.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Adjust the range of playlists to read from and create edges between songs ending up in playlists together (in a dictionary format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_dict = {}\n",
    "start = 100\n",
    "end = 200\n",
    "for row in data.itertuples(index = True):\n",
    "    if row[0] < start:\n",
    "        continue\n",
    "    if row[0] > end:\n",
    "        break\n",
    "    for i in range(len(row[3])):\n",
    "        if row[3][i] not in song_dict:\n",
    "            song_dict[row[3][i]] = []\n",
    "        for song in row[3][i+1:]:\n",
    "            if song not in song_dict[row[3][i]]:\n",
    "                song_dict[row[3][i]].append(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = song_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Read song network into a text file with each line showing a connection: song i --> song j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = open('[test]songnet.txt', 'w')\n",
    "for song_node in songs:\n",
    "    for song_nb in song_dict[song_node]:\n",
    "        line = song_node + ' ' + song_nb\n",
    "        out_file.write(line)\n",
    "        out_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: (Run separately, after text file has been created) Generating a graph for the current song network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of nodes are= 7876\n",
      "No. of edges are= 1299529\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "file_name=\"songnet(mini).txt\"\n",
    "songs=nx.read_edgelist(file_name,create_using=nx.DiGraph())\n",
    "node, edge=songs.order(),songs.size()\n",
    "print(\"No. of nodes are=\",node)\n",
    "print(\"No. of edges are=\",edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib \n",
    "import scipy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import os\n",
    "import community\n",
    "import igraph\n",
    "from community import community_louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_largest_component(generator):\n",
    "    sub_graphs = []\n",
    "    for item in generator:\n",
    "        sub_graphs.append(item)\n",
    "\n",
    "    list_of_all_subgraphs = [(graph, len(graph.nodes)) for graph in sub_graphs]\n",
    "\n",
    "    largest_count = 0\n",
    "    for i in range(len(list_of_all_subgraphs)):\n",
    "        count = list_of_all_subgraphs[i][1]\n",
    "        if count > largest_count:\n",
    "            largest_count = count\n",
    "            largest_component = list_of_all_subgraphs[i][0]\n",
    "    return largest_component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Determining the largest subgraph in the song network (connecting the most number of nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4280"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs_ud = songs.to_undirected()\n",
    "songs_ud_components = nx.connected_component_subgraphs(songs_ud)\n",
    "songs_largest_component = find_largest_component(songs_ud_components)\n",
    "songs_largest_component.number_of_nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: (Optional) Run a community detection on the largest subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_community = community_louvain.best_partition(songs_largest_component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "songs_sorted = sorted_x = sorted(songs_community.items(), key=operator.itemgetter(1))\n",
    "songs_coms = dict(songs_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_degrees = songs_largest_component.degree()\n",
    "songs_degrees = dict(songs_degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_coms = dict(songs_sorted)\n",
    "nx.set_node_attributes(songs_largest_component, songs_coms, \"community\")\n",
    "nx.set_node_attributes(songs_largest_component, songs_degrees, \"degrees\")\n",
    "nx.set_node_attributes(songs_largest_component, songs_community, \"partitions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Write the largest subgraph (our reduced song network) to a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = open('reduced_songnet.txt', 'w')\n",
    "for items in dict(songs_largest_component.edges).keys():\n",
    "    line = items[0] + ' ' + items[1]\n",
    "    out_file.write(line)\n",
    "    out_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gml(songs_largest_component, \"songs_coms_TOTAL.gml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
